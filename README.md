#Capston Project
##Udacity Self-Driving Car Nanodegree 

This is an individual submission. 

### Summary
Since I've only have a MacBook Pro laptop I've choose to work with a VM. Unfortunately the processing power of the machine is not enough to run the VM and the simulator (simulator is not run in the VM) and process the instruction fast enough. So I have a severe latency problem where the simulator receives very outdated data from the ROS server. I've managed to make some improvements so I can at least partially test the solution, but haven't actually manage to run the Camera on and Manual off all the time. 
The same is observed on the Project Workspace.
I submit the project with higher values for the rate of the of the tl_detector, dbw_node, waypoint_updater and pure_pursuit that I have actually tested and will appreciate feed back on your run in the simulator. 

Since individual submissions are not run on Carla :( I've only covered the simulator.

### Waypoint Updater

Following the walkthrough I've replicated the proposed solution with very little tweaks. 

* The node subscribes to 
 * current_pose to have the car current position
 * base_waypoints to get the list of waypoints to follow
 * traffic_waypoint to get the closest traffic stop line waypoint index position with a red signal. 

On each run according to the rate of execution it first finds the closest waypoint in front of the car and then takes the waypoints to look ahead for publishing. If there is a red traffic light waypoint in front it updates the target speed of the waypoints gradually descending to 0. The code also considers not to update the target speed above the preset waypoint speed, which can happen if the distance is great. 

### Drive By Wire Node
The node is responsible for publishing the steering angle throttle and brake values in order to drive the car. It first considers if the dbw_enabled is set to true so it doesn't tries to control the vehicle if the driver is in control. 
It then filters the current velocity since the data might have spikes that should be ignored. 
It then uses YawController to get the steering angle from the set linear velocity and angular velocity which the twist command have set. 
Based on the difference between the current velocity and the desired velocity it determines values for brake and throttle. 

### Traffic light Detection 

A difference from the walkthough is that node is processed on a rate base instead on each coming image. I've trained a classifier for processing the image and determining the traffic light stated based on work done by Alexander Lecher [Traffic Light Classification](https://github.com/alex-lechner/Traffic-Light-Classification#1-the-lazy-approach)
I've also chosen to use [SSD Inception V2 Coco (17/11/2017)](https://github.com/alex-lechner/Traffic-Light-Classification#1-choosing-a-model) model and use the data generated by him. 
